@page
@model BundestagMine.Pages.ResearchCenter.VecTopModel
@{
    ViewData["Title"] = "VecTop";
}

<head>
    <link href="../css/pages/research-center.css" rel="stylesheet">
</head>

<nav class="bg-darkprime-gradient card-shadow">
    <div class="container flexed justify-content-between align-items-center">
        <a class="btn rounded-0" asp-page="/Index">
            <div>
                <img class="logo" src="/img/logo/Logo_weiß_transparent_RGB_534x512.png" />
                <h5 class="ml-2 mb-0 text-light small-font">Bundestags-Mine</h5>
            </div>
        </a>
        <h5 class="m-0 font-weight-bold text-light">
            Research-Center
        </h5>
        <a class="btn rounded-0 hidden">
            <div>
                <img class="logo" src="/img/Logo_weiß_transparent_RGB_534x512.png" />
                <h5 class="ml-2 mb-0 text-light small-font">Bundestags-Mine</h5>
            </div>
        </a>
    </div>
</nav>

<div class="page-wrapper">
    <div class="mt-4 pb-5 container-fluid">
        <div class="container">
            <a class="clickable text-dark" asp-page="Index">
                <i class="fas fa-chevron-left"></i> Übersicht
            </a>

            <div class="alert alert-primary flexed justify-content-between align-items-center mt-3 mb-3">
                <p class="text-black-50 mr-3 mb-0">
                    Laden Sie das Paper zu VecTop herunter, welches kurz die Historie des 
                    Topic Modellings erläutert, um danach VecTop vorzustellen.
                </p>
                <a class="btn btn-light rounded-0 h-100 border-1" target="_blank"
                   asp-action="DownloadVecTopPaper" asp-controller="Research">
                    <i class="mb-2 mt-2 fas fa-file-pdf large-font mr-1"></i>
                    Paper
                </a>
            </div>
            <h5 class="mt-3">Word Embeddings</h5>
            <div>
                <p class="text-black-50">
                    Im Natural Language Processing und in der KI allgemein muss der erste Schritt immer sein, Daten von
                    unterschiedlichen Typen (Bilder, Texte, Videos etc.) in eine numerische Form zu bringen. Nur mit
                    Zahlen kann ein Neuronales Netz lernen. <br />
                    Texte werden dabei typischerweise in Word Embeddings transformiert. Das sind Vektoren mit unterschiedlichen
                    Dimensionen. <b>Die Idee</b>: die Embeddings zweier sehr ähnlicher Texte sollen im Vektorraum auch sehr
                    nah beieinander liegen. Wir kriegen somit mehrere Cluster von kontextual ähnlichen Texten.
                </p>
            </div>
            <hr />
            <h5 class="mt-3">Kosinus Ähnlichkeit</h5>
            <div>
                <p class="text-black-50">
                    Wenn mehrere Texte im Vektorraum durch Word Embeddings abgebildet werden, bedarf es einer
                    Funktion um die Ähnlichkeit zweier Vektoren und damit Texten zu berechnen. Eine davon ist die
                    <b>Kosinus-Ähnlichkeit</b>. Je größer die Ähnlichkeit, desto ähnlicher sind sich die Texte.
                </p>
            </div>
            <hr />
            <h5 class="mt-3">VecTop</h5>
            <div>
                <p class="text-black-50">
                    VecTop nutzt diese beiden Techniken in Verbindung mit Spiegel Online. Durch Webscraping werden
                    huntertausende Artikel des Spiegel Onlines gespeichert. Diese Text werden erst zusammengefasst, da
                    Word Embeddings mit sehr langen Texten Probleme bekommt und danach in Word Embeddings umgewandelt.
                    <b>Die Idee:</b> Spiegel Online ordnet alle Artikel in bestimmte Kategorien ein, zB. Wirtschaft -> Börse.
                    <br />
                    Wenn Sie nun eine Rede im Bundestag kategorisieren möchten, wird diese Rede, sollte sie zu lange sein,
                    zusammengefasst, in Word Embeddings transformiert und auf den Spiegel Online Korpus verglichen.
                    <b>Welche Artikel ähneln kotextual der Rede am Meisten?</b> Diese werden durch die Kosinus-Ähnlichkeit
                    extrahiert und mithilfe der
                    Kategorien aus Spiegel Online gleichzeitig kategorisiert. Eine Rede, die im Vektorraum sehr nah
                    an einem Artikel über die Börse platziert ist, wird somit mit Wirtschaft -> Börse kategorisiert.
                </p>
            </div>
            <hr />
            <h5 class="mt-3">Testen Sie VecTop selbst!</h5>
            <div>
                <p class="text-black-50">
                    Sie möchten selbst Texte für Ihre Zwecke kategorisieren oder einfach mal VecTop ausprobieren?
                    Dann finden Sie eine Live-Demo von VecTop <a href="http://vectop.bundestag-mine.de/" target="_blank">hier</a>!
                    <br />
                    Für die Informatiker: VecTop ist open-source auf GitHub <a href="https://github.com/TheItCrOw/VecTop" target="_blank">hier</a> zu finden.
                </p>
            </div>
            <hr />
        </div>
    </div>
</div>
